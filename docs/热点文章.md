# 1.热点文章

## 热点文章判断标准
- 点赞数量，评论数量，阅读数量，收藏数量
- 把热点数据存入redis进行展示

# 2.定时计算热点文章
![](/resources/热点文章定时计算.png)

- 根据文章的行为（点赞、评论、阅读、收藏）计算文章的分值，利用定时任务每天完成一次计算

- 把分值较大的文章数据存入到redis中

- App端用户查询文章列表的时候，优先从redis中查询热度较高的文章数据

## a) xxl-job 分布式任务调度框架

- 当前软件的架构已经开始向分布式架构转变，将单体结构拆分为若干服务，服务之间通过网络交互来完成业务处理。在分布式架构下，一个服务往往会部署多个实例来运行我们的业务，如果在这种分布式系统环境下运行任务调度，我们称之为**分布式任务调度**。

- XXL-JOB是一个分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。

- 源码地址：https://gitee.com/xuxueli0323/xxl-job

- 文档地址：https://www.xuxueli.com/xxl-job/

- 初始化“调度数据库”
    - xxl_job_lock：任务调度锁表；
    - xxl_job_group：执行器信息表，维护任务执行器信息；
    - xxl_job_info：调度扩展信息表： 用于保存XXL-JOB调度任务的扩展信息，如任务分组、任务名、机器地址、执行器、执行入参和报警邮件等等；
    - xxl_job_log：调度日志表： 用于保存XXL-JOB任务调度的历史信息，如调度结果、执行结果、调度入参、调度机器和执行器等等；
    - xxl_job_logglue：任务GLUE日志：用于保存GLUE更新历史，用于支持GLUE的版本回溯功能；
    - xxl_job_registry：执行器注册表，维护在线的执行器和调度中心机器地址信息；
    - xxl_job_user：系统用户表；

## b) 配置部署调度中心-docker安装
- 创建mysql容器，初始化xxl-job的SQL脚本

```shell
docker run -p 3306:3306 --name mysql57 \
-v /opt/mysql/conf:/etc/mysql \
-v /opt/mysql/logs:/var/log/mysql \
-v /opt/mysql/data:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=root \
-d mysql:5.7
```

- 拉取镜像

```shell
docker pull xuxueli/xxl-job-admin:2.3.0
```
- 创建容器

```shell
docker run -e PARAMS="--spring.datasource.url=jdbc:mysql://192.168.31.125:3306/xxl_job?Unicode=true&characterEncoding=UTF-8 \
--spring.datasource.username=root \
--spring.datasource.password=root" \
-p 8888:8080 -v /tmp:/data/applogs \
--name xxl-job-admin --restart=always  -d xuxueli/xxl-job-admin:2.3.0
```

## c) 热点文章定时计算思路
![](/resources/分值计算.png)

# 3.实时计算热点文章
![](/resources/实时计算.png)

## a) kafka stream实现流式计算

* 流式计算测试类：”KafkaStreamQuickStart“

## b) 实时计算流程
![](/resources/实时计算流程图.png)

- 用户行为（阅读量，评论，点赞，收藏）发送消息
    - 在heima-leadnews-behavior微服务中集成kafka生产者配置
    - 修改ApLikesBehaviorServiceImpl新增发送消息
    - 修改阅读行为的类ApReadBehaviorServiceImpl发送消息
- 使用kafkaStream实时接收消息，聚合内容
    - 在leadnews-article微服务中集成kafkaStream
    - 定义实体类，用于聚合之后的分值封装
    - 定义stream,接收消息并聚合
- 重新计算文章的分值，更新到数据库和缓存中
    - 在ApArticleService添加方法，用于更新数据库中的文章分值
    - 定义监听，接收聚合之后的数据，文章的分值重新进行计算

## c) springboot集成kafka stream

~~~java
package com.heima.kafka.config;

import lombok.Getter;
import lombok.Setter;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafkaStreams;
import org.springframework.kafka.annotation.KafkaStreamsDefaultConfiguration;
import org.springframework.kafka.config.KafkaStreamsConfiguration;

import java.util.HashMap;
import java.util.Map;

/**
 * 通过重新注册KafkaStreamsConfiguration对象，设置自定配置参数
 */

@Setter
@Getter
@Configuration
@EnableKafkaStreams
@ConfigurationProperties(prefix="kafka")
public class KafkaStreamConfig {
    private static final int MAX_MESSAGE_SIZE = 16* 1024 * 1024;
    private String hosts;
    private String group;
    @Bean(name = KafkaStreamsDefaultConfiguration.DEFAULT_STREAMS_CONFIG_BEAN_NAME)
    public KafkaStreamsConfiguration defaultKafkaStreamsConfig() {
        Map<String, Object> props = new HashMap<>();
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, hosts);
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, this.getGroup()+"_stream_aid");
        props.put(StreamsConfig.CLIENT_ID_CONFIG, this.getGroup()+"_stream_cid");
        props.put(StreamsConfig.RETRIES_CONFIG, 10);
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        return new KafkaStreamsConfiguration(props);
    }
}
~~~